# -*- coding: utf-8 -*-
"""AppStoreEDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hhniLpIXn1cH9ts1w2JqG09w31i15T_q

# 1. ABOUT DATA

**Data**:  Apple AppStore Dataset

The dataset was collected from Kaggle [Uploaded by GAUTHAM PRAKASH]

# 2. TASK

We're going to explore the dataset to understand it better through Exploratory Data Analysis (EDA). This exploration will help us identify what needs to be cleaned and normalized in the data. As we write the code, we'll take notes on what we discover. Finally, we'll summarize our findings and draw conclusions from the analysis.

# 3. OBJECTIVES

The main goal of this project is to carefully analyze the dataset to discover important insights. The ultimate aim is to highlight customer behaviors and preferences to developers and other stakeholders. This information will help attract more business for their upcoming applications.

# 4. LIBRARIES USED

1. Pandas: Data manipulation and analysis library.
2. Numpy: Numerical computing library.
3. Matplotlib: Data visualization library.
4. Seaborn: Statistical data visualization library.
5. Scipy: To provide a comprehensive set of numerical algorithms and tools for scientific computing in Python.
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd

import numpy as np

import matplotlib.pyplot as plt

import seaborn as sns

# %matplotlib inline

import scipy as s

"""# 5. Data Loading, Exploration & Wrangling

## 5.1.  Load the csv file with the help of pandas library


      The dataset is collected from Kaggle due to its large dataset we need to
      use parameters like **encoding='latin1'** and **error_bad_lines=False**
      to handle encoding issues and skip lines with errors, respectively.


## 5.2.  Creating the dataframe and understanding the data present in the dataset
"""

chunk_size = 10000

chunks = pd.read_csv('/content/appleAppData.csv', encoding='latin1', error_bad_lines=False, chunksize=chunk_size)

df = pd.concat(chunks, ignore_index=True)

"""## 5.3. **Get a sneak peek of your data** **bold text** **bold text**"""

df

"""## 5.4. View the shape of the dataset"""

print(f"The dataframe has {df.shape[0]} rows and {df.shape[1]} columns")

"""## 5.5. View the column names"""

print(df.columns.values)

"""## 5.6. Display all columns when outputting DataFrames"""

pd.set_option('display.max_columns', None)

df.head(5)

"""## 5.7. Descriptive Statistics"""

df.info()

df.describe()

"""# 6. Missing Values

## 6.1 Check missing values in the data
"""

df.isnull().sum().sort_values(ascending = False)

"""## 6.2 Percentage of null values in the dataset sorted in ascending order"""

missing_percentage = (df.isnull().sum().sort_values(ascending = False)/len(df))*100
missing_percentage

"""## 6.3 Exploratory Analysis

### Provide us the visual on the missing values in a dataframe 'df'
"""

plt.rcParams['figure.figsize'] = (15,6)
sns.heatmap(df.isnull(),yticklabels = False, cbar = False , cmap = 'viridis')
plt.title("Missing null values")

"""### Graphical representation of the percentage of null values"""

missing_percentage = missing_percentage[missing_percentage != 0] # Only the missing data
plt.rcParams['figure.figsize'] = (20,6)
missing_percentage.plot(kind = 'barh')
plt.title("Percentage of null values")

"""## 6.4 Dealing with the null values

### Drop Developer Website

We decided to remove the "Developer Website" information from the dataset because it wasn't relevant to our analysis, and there were many missing (NULL) values associated with it.
"""

df.drop('Developer_Website', axis=1, inplace=True)
df.info()

"""### Filling the Null Values"""

# Convert 'Price' column to numeric values
df['Price'] = pd.to_numeric(df['Price'], errors='coerce')

# Fill NaN values with the mean
df['Price'] = df['Price'].fillna(value=df['Price'].mean())
df['Size_Bytes'] = df['Size_Bytes'].fillna(value=df['Size_Bytes'].mean())

"""### Have a view of refreshed dataset again"""

df.isnull().sum().sort_values(ascending = False)

"""### View those rows where a column has null values"""

df[df['Current_Version_Reviews'].isnull()].head()

df[df['Reviews'].isnull()].head()

df[df['Developer'].isnull()].head()

df[df['DeveloperId'].isnull()].head()

df[df['Free'].isnull()].head()

df[df['Updated'].isnull()].head()

df[df['Currency'].isnull()].head()

"""### Drop those rows where a column has null values"""

df.dropna(subset=['Current_Version_Reviews'], inplace=True)

df.dropna(subset=['Current_Version_Score'], inplace=True)

df.dropna(subset=['Reviews'], inplace=True)

df.dropna(subset=['Average_User_Rating'], inplace=True)

df.dropna(subset=['Developer'], inplace=True)

df.dropna(subset=['Developer_Url '], inplace=True)

df.dropna(subset=['DeveloperId'], inplace=True)

df.dropna(subset=['Updated '], inplace=True)

df.dropna(subset=['Version'], inplace=True)

df.dropna(subset=['Currency '], inplace=True)

df.dropna(subset=['Free '], inplace=True)

"""### Have a view of refreshed dataset again"""

df.isnull().sum().sort_values(ascending = False)

"""# 7.  Find Duplications and Analyse them

## Check Duplicates
"""

df.duplicated().any()

any_duplicates = df.duplicated(subset=['App_Id', 'App_Name', 'AppStore_Url', 'Primary_Genre', 'Content_Rating',
       'Size_Bytes', 'Required_IOS_Version', 'Released', 'Updated', 'Version',
       'Price', 'Currency', 'Free', 'DeveloperId', 'Developer',
       'Developer_Url', 'Average_User_Rating', 'Reviews',
       'Current_Version_Score', 'Current_Version_Reviews']).any()

boolean = df['App_Name'].duplicated().any()
boolean

"""## Count repeating App Names"""

df['App_Name'].value_counts().sort_values(ascending=False)

"""## Check App Name column which multiple rows are identical or not"""

df[df['App_Name'] == 'Web2PDF']

df[df['App_Name'] == 'Audiostories']

df[df['App_Name'] == 'PageWyze']

df[df['App_Name'] == 'EditFire']

df[df['App_Name'] == 'FACTA']

df[df['App_Name'] == 'Calculator â']

"""## Drop the rows that are Identical"""

rows_to_drop = [109068,133863,119563,135387,32813,86998,91311,107546,21309,107770]
df_dropped = df.drop(index=rows_to_drop)

# Drop rows in-place
df.drop(index=rows_to_drop, inplace=True)

"""# 8. Exploring Numeric columns

The unique() function returns an array containing the distinct values present in the specified column.

Each element in the array represents a unique size value found in the column.
"""

df['Size_Bytes'].unique()

df['Price'].unique()

df['Average_User_Rating'].unique()

df['Reviews'].unique()

df['Current_Version_Score'].unique()

df['Currency'].unique()

df['Content_Rating'].unique()

df.head(5)

"""## Adding column to hold Size_Bytes in MBs

creating Size_MB in dataframe
"""

df['Size_MB'] = 0

df.columns

"""Calculate Size in Megabytes (MB)"""

df['Size_MB'] = df['Size_Bytes'].apply(lambda x: (float(x) / 1024)/1024)

"""Descriptive Statistics for 'Average_User_Rating' column"""

df.Average_User_Rating.describe()

"""# 9. Creataing the column type for free and paid Apps"""

df['Type'] = np.where(df['Free'] == True,'Free','Paid')
df.drop(['Free'],axis=1, inplace= True )

df.head(5)

"""Descriptive Statistics for 'Reviews' Column"""

df.Reviews.describe()

"""# 10. Viewing the content of the column 'Content_Rating'

First we will view the unique values present in this column
"""

for i in df.Content_Rating.unique():
    print(i)

"""    we have various Categories in the content Rating column :
    4+
    17+
    9+
    12+
    Not yet rated
    Now, we makes these categories to a simple 4 readable Categories for better understanding :
    Children, Teens, Adults & Everyone

    4+: Children
    17+: Adults
    9+: Children
    12+: Teens
    Not yet rated : Everyone
"""

df["Content_Rating"]=df["Content_Rating"].replace("4+","Children")
df["Content_Rating"]=df["Content_Rating"].replace("9+","Children")
df["Content_Rating"]=df["Content_Rating"].replace("12+","Teens")
df["Content_Rating"]=df["Content_Rating"].replace("17+","Adults")
df["Content_Rating"]=df["Content_Rating"].replace("Not yet rated","Everyone")

"""Presenting the content of the coulumn in Ascending order 'Children', 'Teens', 'Everyone', 'Adults'"""

agegroup = df['Content_Rating'].unique()

# define the order in which you want to print the values
custom_order = ['Children', 'Teens', 'Everyone', 'Adults']

# sort the array in the custom order
sorted_array = sorted(['Children', 'Adults', 'Teens', 'Everyone'], key=lambda x: custom_order.index(x))

# print the sorted array
print(sorted_array)

df.head()

"""# 11. Grouping 'Reviews' into ranges for better data understanding

This step helps categorize individual review counts into specific ranges,
 making it easier to observe patterns and trends in the data.

Check minimum Reviews
"""

df.Reviews.min()

"""Check maximum Reviews"""

df.Reviews.max()

"""Statistical Description"""

df.Reviews.describe()

"""Review column is numeric column that holds information about the number fo reviews users left while dowloading
1. if an app has reviews between 0 and 10000 --> Less than 10K
2. if an app has reviews between 10000 and 500000 --> Between 10K and 500K
3. if an app has reviews between 500000 and 1000000 --> Between 500K and 1Mil
4. if an app has reviews between 1000000 and 22685334 --> Million Plus
"""

# Creating a new 'ReviewCategory' column and initializing it with 'NoReviewsProvided'
df['ReviewCategory'] = 'NoReviewsProvided'

# Categorizing reviews into specific ranges based on count
df.loc[(df['Reviews'] > 0) & (df['Reviews'] <= 10000.0),'ReviewCategory'] = 'Less than 10K'
df.loc[(df['Reviews'] > 10000) & (df['Reviews'] <= 500000.0),'ReviewCategory'] = 'Between 10K and 500K'
df.loc[(df['Reviews'] > 500000) & (df['Reviews'] <= 1000000),'ReviewCategory'] = 'Between 500K and 1Mil'
df.loc[(df['Reviews'] > 1000000) & (df['Reviews'] <= 22685334),'ReviewCategory'] = 'Million Plus'

# Counting the occurrences of each 'ReviewCategory'
df['ReviewCategory'].value_counts()

df.info()

"""We're cleaning up the 'Average_User_Rating' column. Currently, it has decimal values in the range of 0 to 5."""

df["Average_User_Rating"] = df["Average_User_Rating"].round().astype(int)

df.head(5)

df.Average_User_Rating.unique()

"""# 12. Exploratory Analysis and Visualization

## List the top 10 app categories from the Apple Store
"""

top_Genre = df.Primary_Genre.value_counts().reset_index().rename(columns={'Primary_Genre':'Count','index':'Primary_Genre'})

top10_top_Genre = top_Genre.head(10)

top10_top_Genre.head(10)

sns.barplot(top10_top_Genre , x='Primary_Genre', y='Count', color='grey')

"""## Top 10 Primary Genres with the Highest Average User Ratings"""

mean_ratings = df.groupby('Primary_Genre')['Average_User_Rating'].mean()


sorted_ratings = mean_ratings.sort_values(ascending=False)


top_10 = sorted_ratings.head(10)

print(top_10)

"""## Identify the Primary_Genre with the highest count of both Paid and Free apps"""

# group the dataset by Primary_Genre and Type, and count the number of apps in each group
genre_counts = df.groupby(['Primary_Genre', 'Type']).size().reset_index(name='Count')
# # separate the free apps
top10_free_apps = genre_counts[genre_counts['Type'] == 'Free']
# ##load top 10 free apps
top_10_free_genres = top10_free_apps.sort_values(by='Count', ascending=False).head(10)

# top_10_free_genres

# # separate the free apps
top10_paid_apps = genre_counts[genre_counts['Type'] == 'Paid']
# ##load top 10 free apps
top_10_paid_genres = top10_paid_apps.sort_values(by='Count', ascending=False).head(10)

top_10_free_genres.head(5)

top_10_paid_genres.head(5)

"""## Top 5 Paid Apps based with highest ratings"""

top5_paid_apps = df[df['Type'] == 'Paid'].sort_values('Average_User_Rating', ascending=False).head(5)[['App_Name', 'Average_User_Rating']]


print(top5_paid_apps)

"""##  Top 5 Free Apps with the Highest Ratings"""

# sort the paid apps by rating in descending order and select the top 5
top5_free_apps = df[df['Type'] == 'Free'].sort_values('Average_User_Rating', ascending=False).head(5)[['App_Name', 'Average_User_Rating']]

# display the top 5 paid apps and their ratings
print(top5_free_apps)

"""## Apps with highest content rating"""

lst_Content_Rating = df.Content_Rating.value_counts().reset_index().rename(columns={'Content_Rating':'Count','index':'Content_Rating'})
lst_Content_Rating.sort_values(by='Count', ascending=False)

"""## Years with the Most App Releases"""

df['Released'] = pd.to_datetime(df['Released']) # convert to datetime format
df['Year_Release'] = df['Released'].dt.strftime('%Y')
cnt_year_app_Release = df.groupby(['Year_Release']).size().reset_index(name='Count')
cnt_year_app_Release.head(20).sort_values(by='Count', ascending=False)

sns.barplot(cnt_year_app_Release , x='Year_Release', y='Count', color='grey')

"""## Size in MBs vs. Price of App"""

# group the dataset by Primary_Genre and Type, and count the number of apps in each group
Tot_Apps_Size_Price = df.groupby(['Size_MB', 'Price']).size().reset_index(name='Count')

# ##load top 10 free apps
Top10_Apps_Size_Price = Tot_Apps_Size_Price.sort_values(by='Size_MB', ascending=False).head(10)
Top10_Apps_Size_Price

"""Plot showing the size of the app in MB and its price"""

sns.barplot(Top10_Apps_Size_Price, x='Size_MB', y='Price', color='grey')

"""The pair-plot above further highlights the relation of Free and Paid app with the price"""

sns.pairplot(df, hue='Type', vars=['Size_MB', 'Price'])

"""##  Top 10 App producing Developer"""

# group the dataset by Primary_Genre and Type, and count the number of apps in each group
Top10_Cnt_Dev = df.groupby(['Developer']).size().reset_index(name='Count')

# ##load top 10 free apps
Top10_Cnt_App_Dev = Top10_Cnt_Dev.sort_values(by='Count', ascending=False).head(10)

Top10_Cnt_App_Dev.head(10)

"""A pie chart showing which Developer or company has highest app development contribution to the app store"""

plt.figure(figsize=(8,6))
data = Top10_Cnt_App_Dev.groupby('Developer')['Count'].max().sort_values(ascending = True)
data = data.head(10)
labels = data.keys()
plt.pie(data, labels= labels,autopct='%.0f%%')
plt.title(" Top 10 App Producing developer", fontsize=14)

"""##  Genre-wise revenue analysis for different customer demographics

Shows which genre attracted what kind of clintele in terms of revenues
"""

df.groupby(['Primary_Genre', 'Content_Rating'])['Price'].sum().unstack().plot(kind='bar', stacked=True)

# select the rows where Content_Rating is Toddlers and Primary_Genre is Business
toddler_business_df = df[(df['Content_Rating'] == 'Children') & (df['Primary_Genre'] == 'Business')]

# print the resulting DataFrame
toddler_business_df.head(5)

# select the rows where Content_Rating is Toddlers and Primary_Genre is Business
toddler_utility_df = df[(df['Content_Rating'] == 'Children') & (df['Primary_Genre'] == 'Utilities')]

# print the resulting DataFrame
toddler_utility_df.head(5)

"""## Comparison of apps per Content_Rating

Year on Year engagement of various age groups as categorised by App Store
"""

cnt_YoY = df.groupby(['Year_Release', 'Content_Rating', 'Primary_Genre']).size().reset_index(name='Count')
#cnt_year_app_Release.head(10).sort_values(by='Count', ascending=False)

cnt_YoY.groupby(['Year_Release', 'Content_Rating'])['Count'].sum().unstack().plot(kind='bar', stacked=True)

"""##  User Rating vs Price"""

usr_Rat_Pri = df.groupby(['Average_User_Rating', 'Year_Release'])[['Price']].sum()


usr_Rat_Pri.groupby(['Year_Release', 'Average_User_Rating'])['Price'].sum().unstack().plot(kind='bar', stacked=True)

"""##  User Rating vs MBytes"""

usr_Rat_MB = df.groupby(['Average_User_Rating', 'Year_Release'])[['Size_MB']].sum()
# usr_Rat_Pri

usr_Rat_MB.groupby(['Year_Release', 'Average_User_Rating'])['Size_MB'].sum().unstack().plot(kind='bar', stacked=True)

"""## Top-5 Genre based on App Price

Year on Year break down of top-5 Genre based on App Price
"""

Rev_per_Genre = df.groupby(['Year_Release','Primary_Genre' ])[['Price']].sum()


top5_genres = (Rev_per_Genre
                       .sort_values(['Year_Release', 'Price'], ascending=[True, False])
                       .groupby('Year_Release')
                       .head(5))

# Define a colormap: To present each category with a different color
cmap = plt.get_cmap('tab20')


# Group by year and primary genre, and plot a stacked bar chart
top5_genres.groupby(['Year_Release', 'Primary_Genre'])['Price'].sum().unstack().plot(kind='bar', stacked=True, title= "Year on Year break down of top-5 Genre based on App Price", cmap=cmap)

# Customize the plot
plt.xlabel('Year')
plt.ylabel('Total Price')
plt.legend(title='Primary Genre', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

"""##  IOS Versions Vs Count of app"""

# group the dataset by Primary_Genre and Type, and count the number of apps in each group
Ver_counts = df.groupby(['Required_IOS_Version']).size().reset_index(name='Count')



# ##load top 10 free apps
top_10_Ver_counts = Ver_counts.sort_values(by='Count', ascending=False).head(10)

sns.barplot(top_10_Ver_counts , x='Required_IOS_Version', y='Count', color='grey')

"""## Interdependency of numeric attributes on each other"""

df.corr()

plt.figure(figsize=(8,6))
sns.heatmap(df.corr(),cbar= True, cmap='coolwarm')

"""# 13. Save Data"""

# Saving the pre-processed Dataset
df.to_csv('clean_data.csv', index=False)

"""# THANK YOU"""